{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d53319",
   "metadata": {},
   "source": [
    "# 1. Preprocess data set and performing EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32614a6",
   "metadata": {},
   "source": [
    "In this section we have described how we will preprocess data set by reading files from S3\n",
    "- Input: S3 files in csv format \n",
    "- Output: Preprocess data which can be used for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027979ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be384d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##option--Installing Kaggle API for data set download##\n",
    "! pip install kaggle --upgrade\n",
    "#kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3, os\n",
    "# boto3.Session().resource('s3').Bucket('poc-sagemaker-step-function-bucketformodelanddata-iip9wy7qh0y0').Object(os.path.join('train', 'train_data.csv')).upload_file('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d901b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1e2d64f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 59.8 KiB/59.8 KiB (644.7 KiB/s) with 1 file(s) remaining\r",
      "upload: ./train.csv to s3://ds-mlops-dev/titanic/data/input/inputdata.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp train.csv s3://ds-mlops-dev/titanic/data/input/inputdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4f844b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/WipCoe/Notebooks_LatestCode/WiproFormat\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4dd43",
   "metadata": {},
   "source": [
    "describing dataset which we have got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed5c4f",
   "metadata": {},
   "source": [
    "Removing unnessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at numeric and categorical values separately \n",
    "df_num = df[['Age','SibSp','Parch','Fare']]\n",
    "df_cat = df[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440f16d",
   "metadata": {},
   "source": [
    "Imputing data for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f092ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distributions for all numeric variables \n",
    "from matplotlib import pyplot as plt\n",
    "for i in df_num.columns:\n",
    "    plt.hist(df_num[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3196cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(df_num.corr())\n",
    "sns.heatmap(df_num.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare survival rate across Age, SibSp, Parch, and Fare \n",
    "pd.pivot_table(df, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_cat.columns:\n",
    "    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin - Simplify cabins (evaluated if cabin letter (cabin_adv) or the purchase of tickets across multiple cabins (cabin_multiple) impacted survival)\n",
    "\n",
    "# Tickets - Do different ticket types impact survival rates?\n",
    "\n",
    "# Does a person's title relate to survival rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.Cabin\n",
    "df['cabin_multiple'] = df.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n",
    "# after looking at this, we may want to look at cabin by letter or by number. Let's create some categories for this \n",
    "# letters \n",
    "# multiple letters \n",
    "df['cabin_multiple'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba57448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing for Model\n",
    "# Drop null values from Embarked (only 2)\n",
    "\n",
    "# Include only relevant variables (Since we have limited data, I wanted to exclude things like name and passanger ID so that we could have a reasonable number of features for our models to deal with) Variables: 'Pclass', 'Sex','Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'cabin_adv', 'cabin_multiple', 'numeric_ticket', 'name_title'\n",
    "\n",
    "# Do categorical transforms on all data. Usually we would use a transformer, but with this approach we can ensure that our traning and test data have the same colums. We also may be able to infer something about the shape of the test data through this method. I will stress, this is generally not recommend outside of a competition (use onehot encoder).\n",
    "\n",
    "# Impute data with mean for fare and age (Should also experiment with median)\n",
    "\n",
    "# Normalized fare using logarithm to give more semblance of a normal distribution\n",
    "\n",
    "# Scaled data 0-1 with standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train_test'] = 1\n",
    "#df_test=pd.read_csv(\"test.csv\")\n",
    "#df_test['train_test'] = 0\n",
    "#df_test['Survived'] = np.NaN\n",
    "all_data = pd.concat([df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create all categorical variables that we did above for both training and test sets \n",
    "all_data['cabin_multiple'] = all_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n",
    "all_data['cabin_adv'] = all_data.Cabin.apply(lambda x: str(x)[0])\n",
    "all_data['numeric_ticket'] = all_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "all_data['ticket_letters'] = all_data.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\n",
    "all_data['name_title'] = all_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "#impute nulls for continuous data \n",
    "#all_data.Age = all_data.Age.fillna(training.Age.mean())\n",
    "all_data.Age = all_data.Age.fillna(df.Age.median())\n",
    "#all_data.Fare = all_data.Fare.fillna(training.Fare.mean())\n",
    "all_data.Fare = all_data.Fare.fillna(df.Fare.median())\n",
    "#drop null 'embarked' rows. Only 2 instances of this in training and 0 in test \n",
    "all_data.dropna(subset=['Embarked'],inplace = True)\n",
    "#tried log norm of sibsp (not used)\n",
    "all_data['norm_sibsp'] = np.log(all_data.SibSp+1)\n",
    "all_data['norm_sibsp'].hist()\n",
    "# log norm of fare (used)\n",
    "all_data['norm_fare'] = np.log(all_data.Fare+1)\n",
    "all_data['norm_fare'].hist()\n",
    "# converted fare to category for pd.get_dummies()\n",
    "all_data.Pclass = all_data.Pclass.astype(str)\n",
    "#created dummy variables from categories (also can use OneHotEncoder)\n",
    "all_dummies = pd.get_dummies(all_data[['Survived','Pclass','Sex','Age','SibSp','Parch','norm_fare','Embarked','cabin_adv','cabin_multiple','numeric_ticket','name_title']])\n",
    "#Split to train test again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07033a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>norm_fare</th>\n",
       "      <th>cabin_multiple</th>\n",
       "      <th>numeric_ticket</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>...</th>\n",
       "      <th>name_title_Master</th>\n",
       "      <th>name_title_Miss</th>\n",
       "      <th>name_title_Mlle</th>\n",
       "      <th>name_title_Mme</th>\n",
       "      <th>name_title_Mr</th>\n",
       "      <th>name_title_Mrs</th>\n",
       "      <th>name_title_Ms</th>\n",
       "      <th>name_title_Rev</th>\n",
       "      <th>name_title_Sir</th>\n",
       "      <th>name_title_the Countess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.563674</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.877591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>1.366380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.255451</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.796281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.438050</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>1.066796</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.438050</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.781901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.178396</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.330815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.794841</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>0.491068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.101340</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>2.006119</td>\n",
       "      <td>0.245663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.255451</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>0.491068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.816755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived       Age     SibSp     Parch  norm_fare  cabin_multiple  \\\n",
       "0           0 -0.563674  0.431350 -0.474326  -0.877591               0   \n",
       "1           1  0.669217  0.431350 -0.474326   1.366380               1   \n",
       "2           1 -0.255451 -0.475199 -0.474326  -0.796281               0   \n",
       "3           1  0.438050  0.431350 -0.474326   1.066796               1   \n",
       "4           0  0.438050 -0.475199 -0.474326  -0.781901               0   \n",
       "..        ...       ...       ...       ...        ...             ...   \n",
       "886         0 -0.178396 -0.475199 -0.474326  -0.330815               0   \n",
       "887         1 -0.794841 -0.475199 -0.474326   0.491068               1   \n",
       "888         0 -0.101340  0.431350  2.006119   0.245663               0   \n",
       "889         1 -0.255451 -0.475199 -0.474326   0.491068               1   \n",
       "890         0  0.206883 -0.475199 -0.474326  -0.816755               0   \n",
       "\n",
       "     numeric_ticket  Pclass_1  Pclass_2  Pclass_3  ...  name_title_Master  \\\n",
       "0                 0         0         0         1  ...                  0   \n",
       "1                 0         1         0         0  ...                  0   \n",
       "2                 0         0         0         1  ...                  0   \n",
       "3                 1         1         0         0  ...                  0   \n",
       "4                 1         0         0         1  ...                  0   \n",
       "..              ...       ...       ...       ...  ...                ...   \n",
       "886               1         0         1         0  ...                  0   \n",
       "887               1         1         0         0  ...                  0   \n",
       "888               0         0         0         1  ...                  0   \n",
       "889               1         1         0         0  ...                  0   \n",
       "890               1         0         0         1  ...                  0   \n",
       "\n",
       "     name_title_Miss  name_title_Mlle  name_title_Mme  name_title_Mr  \\\n",
       "0                  0                0               0              1   \n",
       "1                  0                0               0              0   \n",
       "2                  1                0               0              0   \n",
       "3                  0                0               0              0   \n",
       "4                  0                0               0              1   \n",
       "..               ...              ...             ...            ...   \n",
       "886                0                0               0              0   \n",
       "887                1                0               0              0   \n",
       "888                1                0               0              0   \n",
       "889                0                0               0              1   \n",
       "890                0                0               0              1   \n",
       "\n",
       "     name_title_Mrs  name_title_Ms  name_title_Rev  name_title_Sir  \\\n",
       "0                 0              0               0               0   \n",
       "1                 1              0               0               0   \n",
       "2                 0              0               0               0   \n",
       "3                 1              0               0               0   \n",
       "4                 0              0               0               0   \n",
       "..              ...            ...             ...             ...   \n",
       "886               0              0               1               0   \n",
       "887               0              0               0               0   \n",
       "888               0              0               0               0   \n",
       "889               0              0               0               0   \n",
       "890               0              0               0               0   \n",
       "\n",
       "     name_title_the Countess  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "..                       ...  \n",
       "886                        0  \n",
       "887                        0  \n",
       "888                        0  \n",
       "889                        0  \n",
       "890                        0  \n",
       "\n",
       "[889 rows x 41 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "encoded_df = all_dummies.copy()\n",
    "encoded_df[['Age','SibSp','Parch','norm_fare']]= scale.fit_transform(all_dummies_scaled[['Age','SibSp','Parch','norm_fare']])\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b839f69",
   "metadata": {},
   "source": [
    "We'll then split the dataset into training (70%), validation (20%), and test (10%) datasets and convert the datasets to the right format the algorithm expects. We will use training and validation datasets during training. Test dataset will be used to evaluate model performance after it is deployed to an endpoint.\n",
    "\n",
    "Amazon SageMaker's XGBoost algorithm expects data in the libSVM or CSV data format.  For this example, we'll stick to CSV.  Note that the first column must be the target variable and the CSV should not include headers.  Also, notice that although repetitive it's easiest to do this after the train|validation|test split rather than before.  This avoids any misalignment issues due to random reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac8b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(encoded_df.sample(frac=1, random_state=1729), [int(0.7 * len(encoded_df)), int(0.9*len(encoded_df))])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00c29aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 41)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a1fe44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 41)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad76eb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 41)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297ca13",
   "metadata": {},
   "source": [
    "**Exporting data set to s3 bucket without header**\n",
    "## please change below S3 path as per the VW bucket name and folder location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04e3e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('s3://wi-cred-datalake-dev-raw/titanic/input/lrtrain/train.csv', index=False, header=False)\n",
    "validation_data.to_csv('s3://wi-cred-datalake-dev-raw/titanic/input/lrvalidation/validation_data.csv', index=False, header=False)\n",
    "test_data.to_csv('s3://wi-cred-datalake-dev-raw/titanic/input/lrtest/test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edcb090",
   "metadata": {},
   "source": [
    "## 2. Building model\n",
    "\n",
    "In this section we will decribe how we will build model with XGboost inbuilt model and here we will pass hyperparameter to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6a8b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import boto3\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import datetime\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "# sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "#ec2\n",
    "Instance_Type = \"ml.m5.xlarge\"\n",
    "VolumeSizeIn_GB = 1\n",
    "Instance_Count = 1\n",
    "#setup container\n",
    "container = get_image_uri(region, \"linear-learner\")\n",
    "#s3\n",
    "#################\n",
    "#- Please change as per the relevant S3 bucket name\n",
    "bucket = \"wi-cred-datalake-dev-raw\"\n",
    "prefix = \"titanic/input\"\n",
    "##############\n",
    "#input\n",
    "data_bucket = bucket\n",
    "data_prefix = prefix\n",
    "data_bucket_path = f\"s3://{data_bucket}\"\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# output\n",
    "output_bucket = sagemaker.Session().default_bucket()\n",
    "output_prefix = 'titanic/output'\n",
    "output_bucket_path = f\"s3://{output_bucket}\"\n",
    "\n",
    "##Plase change as per VW Config\n",
    "#sec_groups = [\"sg-044e0e7ce4f5721c0\"]\n",
    "#subnets = [\"subnet-0cf0e3f46326aa259\",\"subnet-0156b7f5500cf0b78\",\"subnet-032420199163cff9b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9291baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::525102048888:role/SagemakerCustomRoleForForecast\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48426dc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup_Hyperparameter_Tuning \n",
    "*Note, with the default setting below, the hyperparameter tuning job can take about 30 minutes to complete.*\n",
    "\n",
    "\n",
    "Now that we have prepared the dataset, we are ready to train models. Before we do that, one thing to note is there are algorithm settings which are called \"hyperparameters\" that can dramtically affect the performance of the trained models. For example, XGBoost algorithm has dozens of hyperparameters and we need to pick the right values for those hyperparameters in order to achieve the desired model training results. Since which hyperparameter setting can lead to the best result depends on the dataset as well, it is almost impossible to pick the best hyperparameter setting without searching for it, and a good search algorithm can search for the best hyperparameter setting in an automated and effective way.\n",
    "\n",
    "We will use SageMaker hyperparameter tuning to automate the searching process effectively. Specifically, we specify a range, or a list of possible values in the case of categorical hyperparameters, for each of the hyperparameter that we plan to tune. SageMaker hyperparameter tuning will automatically launch multiple training jobs with different hyperparameter settings, evaluate results of those training jobs based on a predefined \"objective metric\", and select the hyperparameter settings for future attempts based on previous results. For each hyperparameter tuning job, we will give it a budget (max number of training jobs) and it will complete once that many training jobs have been executed.\n",
    "\n",
    "In this example, we are using SageMaker Python SDK to set up and manage the hyperparameter tuning job. We first configure the training jobs the hyperparameter tuning job will launch by initiating an estimator, which includes:\n",
    "* The container image for the algorithm (XGBoost)\n",
    "* Configuration for the output of the training jobs\n",
    "* The values of static algorithm hyperparameters, those that are not specified will be given default values\n",
    "* The type and number of instances to use for the training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75adc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup sagemaker SDK\n",
    "client = boto3.client(\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e2224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.c4.xlarge',\n",
    "                                       output_path = output_bucket_path,\n",
    "                                       sagemaker_session = sess)\n",
    "\n",
    "linear.set_hyperparameters(\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 20,\n",
    "                           epochs = 50,\n",
    "                           num_models = 10,\n",
    "                           loss = 'absolute_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2b4f3",
   "metadata": {},
   "source": [
    "We will tune four hyperparameters in this examples:\n",
    "* *eta*: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative. \n",
    "* *alpha*: L1 regularization term on weights. Increasing this value makes models more conservative. \n",
    "* *min_child_weight*: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this simply corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is. \n",
    "* *max_depth*: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98aa45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'mini_batch_size': CategoricalParameter([32,64,128,256,512]),\n",
    "                        'learning_rate': ContinuousParameter(0.0001, 1),\n",
    "                        'l1': ContinuousParameter(0.0001, 1)\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ea2f5",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. Since we are using built-in XGBoost algorithm here, it emits two predefined metrics: *validation:auc* and *train:auc*, and we elected to monitor *validation:auc* as you can see below. In this case, we only need to specify the metric name and do not need to provide regex. If you bring your own algorithm, your algorithm emits metrics by itself. In that case, you'll need to add a MetricDefinition object here to define the format of those metrics through regex, so that SageMaker knows how to extract those metrics from your CloudWatch logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31c5e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:objective_loss:final'\n",
    "objective_type = 'Minimize'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e11be",
   "metadata": {},
   "source": [
    "Now, we'll create a `HyperparameterTuner` object, to which we pass:\n",
    "- The XGBoost estimator we created above\n",
    "- Our hyperparameter ranges\n",
    "- Objective metric name and definition\n",
    "- Tuning resource configurations such as Number of training jobs to run in total and how many training jobs can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f282b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(linear,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=1,\n",
    "                            max_parallel_jobs=1,\n",
    "                            early_stopping_type='Auto',\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5ed15",
   "metadata": {},
   "source": [
    "## Launch_Hyperparameter_Tuning\n",
    "Now we can launch a hyperparameter tuning job by calling *fit()* function. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b9c2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://wi-cred-datalake-dev-raw/titanic/input/lrtrain/train.csv\n",
      "s3://wi-cred-datalake-dev-raw/titanic/input/lrvalidation/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "print('{}/{}/lrtrain/train.csv'.format(data_bucket_path, data_prefix))\n",
    "print('{}/{}/lrvalidation/validation_data.csv'.format(data_bucket_path, data_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfac8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................!\n"
     ]
    }
   ],
   "source": [
    "s3_input_train = TrainingInput(s3_data='{}/{}/lrtrain/train.csv'.format(data_bucket_path, data_prefix), content_type='text/csv')\n",
    "s3_input_validation = TrainingInput(s3_data='{}/{}/lrvalidation/validation_data.csv'.format(data_bucket_path, data_prefix), content_type='text/csv')\n",
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f2b0e",
   "metadata": {},
   "source": [
    "Let's just run a quick check of the hyperparameter tuning jobs status to make sure it started successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eed00cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_bucket_path,data_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "333d04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = tuner.latest_tuning_job.job_name # Get name of hpo job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ccd78",
   "metadata": {},
   "source": [
    "# Analyze Results of a Hyperparameter Tuning job\n",
    "\n",
    "Once you have completed a tuning job, (or even while the job is still running) you can use this notebook to analyze the results to understand how each hyperparameter effects the quality of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006251d9",
   "metadata": {},
   "source": [
    "## Track hyperparameter tuning job progress and print best result\n",
    "After you launch a tuning job, you can see its progress by calling describe_tuning_job API. The output from describe-tuning-job is a JSON object that contains information about the current state of the tuning job. You can call list_training_jobs_for_tuning_job to see a detailed list of the training jobs that the tuning job launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "332dab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training jobs have completed\n",
      "Best performing hyper parameters : {'l1': '0.0014121036264995773', 'learning_rate': '0.012104062065442999', 'mini_batch_size': '256'}\n",
      "Result :  {'MetricName': 'validation:objective_loss:final', 'Value': 0.2061675488948822}\n"
     ]
    }
   ],
   "source": [
    "# run this cell to check current status of hyperparameter tuning job\n",
    "region = boto3.Session().region_name\n",
    "sage_client = boto3.Session().client('sagemaker')\n",
    "tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)\n",
    "\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "if status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "best_hyper_parameter = tuning_job_result['BestTrainingJob']['TunedHyperParameters']\n",
    "print(\"Best performing hyper parameters :\",best_hyper_parameter)\n",
    "\n",
    "result = tuning_job_result['BestTrainingJob']['FinalHyperParameterTuningJobObjectiveMetric']\n",
    "print(\"Result : \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e17dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameter={'l1': '0.0014121036264995773', 'learning_rate': '0.012104062065442999', 'mini_batch_size': '256'}\n",
    "ll_best_hyper_parameter = best_hyper_parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec395f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014121036264995773 0.012104062065442999 256\n",
      "{'l1': '0.0014121036264995773', 'learning_rate': '0.012104062065442999', 'mini_batch_size': '256'}\n"
     ]
    }
   ],
   "source": [
    "print(ll_best_hyper_parameter['l1'],ll_best_hyper_parameter['learning_rate'],ll_best_hyper_parameter['mini_batch_size'])\n",
    "print(ll_best_hyper_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e81c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'll_best_hyper_parameter' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store ll_best_hyper_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e80f7e",
   "metadata": {},
   "source": [
    "**Creating model for Linear Learner by passing hyper parameter**\n",
    "\n",
    "Once we have tunned parameter we will generate our model for scoring activities on sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5168480",
   "metadata": {},
   "outputs": [],
   "source": [
    "{output_bucket_path},{output_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1b0ae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job titanic-linear-learner1659327776\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "CPU times: user 66.8 ms, sys: 1.18 ms, total: 68 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "job_name = 'titanic-linear-learner' + str(datetime.datetime.now().timestamp()).split('.')[0]\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "# Ensure that the training and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n",
    "create_training_params = {\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": f\"{output_bucket_path}/{output_prefix}/output\"},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": Instance_Count, \"InstanceType\": Instance_Type, \"VolumeSizeInGB\": VolumeSizeIn_GB},\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\"predictor_type\" :'regressor',\n",
    "                        \"epochs\":\"20\",\n",
    "                        \"l1\":ll_best_hyper_parameter['l1'],\n",
    "                        \"learning_rate\":ll_best_hyper_parameter['learning_rate'],\n",
    "                        \"mini_batch_size\":ll_best_hyper_parameter['mini_batch_size']\n",
    "                       },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 3600},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": f\"s3://wi-cred-datalake-dev-raw/titanic/input/lrtrain/train.csv\",\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/csv\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\":f\"s3://wi-cred-datalake-dev-raw/titanic/input/lrvalidation/validation_data.csv\",\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/csv\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "client.create_training_job(**create_training_params)\n",
    "\n",
    "#track execution\n",
    "status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "print(status)\n",
    "while status != \"Completed\" and status != \"Failed\":\n",
    "    time.sleep(60)\n",
    "    status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93fae749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# checking training job status after creating training job\n",
    "status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2da76d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path: >> s3://sagemaker-us-east-1-525102048888/titanic/output/output\n"
     ]
    }
   ],
   "source": [
    "# printing model output location\n",
    "print(f\"model path: >> {output_bucket_path}/{output_prefix}/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07814516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the training metrics you can tune and generate model as per need\n",
    "metrics = client.describe_training_job(TrainingJobName=job_name)[\"FinalMetricDataList\"]\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926170e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding job name \n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76826bc",
   "metadata": {},
   "source": [
    "**Note:** you will need folowing values in next section\n",
    "- hyperparameter\n",
    "- training job name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ca865",
   "metadata": {},
   "source": [
    "## 3. Generate model on Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a254c",
   "metadata": {},
   "source": [
    "In section we will describe how we can create a model with our training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97d973a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = 'Titanic-linear-learner' # It need to be unique across the account\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\", \n",
    "                              region_name=region)\n",
    "client = boto3.client(\"sagemaker\", \n",
    "                      region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b89a4a",
   "metadata": {},
   "source": [
    "Check if model with same name exists or not. If it exist then delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60ce2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker') # getting sagemaker client \n",
    "try:\n",
    "    client.delete_model(\n",
    "        ModelName=model_name # delete if some model exist with this name\n",
    "    )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45e11441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(region, \"linear-learner\") # getting container image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb529fb0",
   "metadata": {},
   "source": [
    "**Register model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73161602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic-linear-learner\n",
      "s3://sagemaker-us-east-1-525102048888/titanic/output/output/titanic-linear-learner1659327776/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-1:525102048888:model/titanic-linear-learner\n"
     ]
    }
   ],
   "source": [
    "# Here we are registering our model\n",
    "print(model_name) \n",
    "info = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(model_data)\n",
    "primary_container = {\"Image\": container, \"ModelDataUrl\": model_data}\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=primary_container\n",
    "#     VpcConfig={\n",
    "#             'SecurityGroupIds':sec_groups,\n",
    "#             'Subnets': subnets\n",
    "#             }\n",
    ")\n",
    "print(create_model_response[\"ModelArn\"]) # printing model ARN which is cretaed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63f05ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic-linear-learner\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d076e8d",
   "metadata": {},
   "source": [
    "**Note :** \n",
    "- We will need this model ARN for generating endpoint \n",
    "- Also model name need to be unique in an aws account\n",
    "- In case if we need to regenerate model we have to delete existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c583283",
   "metadata": {},
   "source": [
    "## 4. Delete endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fda16afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\", region_name=region)\n",
    "client = boto3.client(\"sagemaker\", region_name=region)\n",
    "endpoint_config_name = 'Titanic-linear-learner-endpoint-config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ce23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker') # getting sagemaker client \n",
    "try:\n",
    "    client.delete_endpoint_config(\n",
    "     EndpointConfigName=endpoint_config_name\n",
    "    )\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32199e39",
   "metadata": {},
   "source": [
    "## 5. Create endpoint config\n",
    "In this section we will describe how we can create a model endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940861d",
   "metadata": {},
   "source": [
    "For generating sagemaker end point we will need to generate endpoint config. So generating endpoint config first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95ab26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'Titanic-learner-endpoint-config'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\", region_name=region)\n",
    "client = boto3.client(\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec4b18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance config for endpoint\n",
    "Instance_Type = \"ml.m5.xlarge\"\n",
    "VolumeSizeIn_GB = 20\n",
    "Instance_Count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "067167e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic-learner-endpoint-config\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:525102048888:endpoint-config/titanic-learner-endpoint-config\n"
     ]
    }
   ],
   "source": [
    "# Creating endpoint config\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": Instance_Type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    "    DataCaptureConfig={\n",
    "        'EnableCapture': True,\n",
    "        'InitialSamplingPercentage': 100,\n",
    "        'DestinationS3Uri': 's3://wi-cred-datalake-dev-raw/capture/', #pls change as per VW settings\n",
    "        'CaptureOptions': [\n",
    "            {\n",
    "                'CaptureMode': 'Input'\n",
    "            },\n",
    "             {\n",
    "                'CaptureMode': 'Output'\n",
    "            },\n",
    "        ],\n",
    "        'CaptureContentTypeHeader': {\n",
    "            'CsvContentTypes': [\n",
    "                'text/csv',\n",
    "            ],\n",
    "            'JsonContentTypes': [\n",
    "                'application/json',\n",
    "            ]\n",
    "        }        \n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Endpoint Config Arn: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9a6cd",
   "metadata": {},
   "source": [
    "**Note :** We will use able endpoint config name to cretae model endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f9796",
   "metadata": {},
   "source": [
    "Incase if you want to delete endpoint config and recreate it we can use below code snippet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e4570",
   "metadata": {},
   "source": [
    "## 6.Create Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ebdc5",
   "metadata": {},
   "source": [
    "In this notebook we create endpoint using endpoint which we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e0aa5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete existing end point\n",
    "endpoint_name = 'Titanic-linear-learner-endpoint'\n",
    "client = boto3.client('sagemaker') # getting sagemaker client \n",
    "try:\n",
    "    client.delete_endpoint(\n",
    "     EndpointName=endpoint_name\n",
    "    )\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ac0d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required library\n",
    "import sys\n",
    "import math\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time    \n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\", region_name=region)\n",
    "client = boto3.client(\"sagemaker\", region_name=region)\n",
    "endpoint_name = endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ce64511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic-linear-learner-endpoint\n",
      "arn:aws:sagemaker:us-east-1:525102048888:endpoint/titanic-linear-learner-endpoint\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Arn: arn:aws:sagemaker:us-east-1:525102048888:endpoint/titanic-linear-learner-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "# Creating model endpoint\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Status: {status}\")\n",
    "    time.sleep(60)\n",
    "    resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "\n",
    "print(f\"Arn: {resp['EndpointArn']}\")\n",
    "print(f\"Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09750eb0",
   "metadata": {},
   "source": [
    "## 7. Validate scoring\n",
    "\n",
    "In this section we will validate scoring logics. In below code snippet we are scoring with 14 predictor values and finding the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a437853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>norm_fare</th>\n",
       "      <th>cabin_multiple</th>\n",
       "      <th>numeric_ticket</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>...</th>\n",
       "      <th>name_title_Master</th>\n",
       "      <th>name_title_Miss</th>\n",
       "      <th>name_title_Mlle</th>\n",
       "      <th>name_title_Mme</th>\n",
       "      <th>name_title_Mr</th>\n",
       "      <th>name_title_Mrs</th>\n",
       "      <th>name_title_Ms</th>\n",
       "      <th>name_title_Rev</th>\n",
       "      <th>name_title_Sir</th>\n",
       "      <th>name_title_the Countess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1</td>\n",
       "      <td>0.283939</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>2.006119</td>\n",
       "      <td>0.348233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>0</td>\n",
       "      <td>3.443222</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.813806</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.180120</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>2.006119</td>\n",
       "      <td>1.899046</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>-0.330815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.178396</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>-0.474326</td>\n",
       "      <td>1.441480</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived       Age     SibSp     Parch  norm_fare  cabin_multiple  \\\n",
       "506         1  0.283939 -0.475199  2.006119   0.348233               0   \n",
       "851         0  3.443222 -0.475199 -0.474326  -0.813806               0   \n",
       "435         1 -1.180120  0.431350  2.006119   1.899046               2   \n",
       "747         1  0.052771 -0.475199 -0.474326  -0.330815               0   \n",
       "681         1 -0.178396 -0.475199 -0.474326   1.441480               1   \n",
       "\n",
       "     numeric_ticket  Pclass_1  Pclass_2  Pclass_3  ...  name_title_Master  \\\n",
       "506               1         0         1         0  ...                  0   \n",
       "851               1         0         0         1  ...                  0   \n",
       "435               1         1         0         0  ...                  0   \n",
       "747               1         0         1         0  ...                  0   \n",
       "681               0         1         0         0  ...                  0   \n",
       "\n",
       "     name_title_Miss  name_title_Mlle  name_title_Mme  name_title_Mr  \\\n",
       "506                0                0               0              0   \n",
       "851                0                0               0              1   \n",
       "435                1                0               0              0   \n",
       "747                1                0               0              0   \n",
       "681                0                0               0              1   \n",
       "\n",
       "     name_title_Mrs  name_title_Ms  name_title_Rev  name_title_Sir  \\\n",
       "506               1              0               0               0   \n",
       "851               0              0               0               0   \n",
       "435               0              0               0               0   \n",
       "747               0              0               0               0   \n",
       "681               0              0               0               0   \n",
       "\n",
       "     name_title_the Countess  \n",
       "506                        0  \n",
       "851                        0  \n",
       "435                        0  \n",
       "747                        0  \n",
       "681                        0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8221f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [{\"score\": 0.7388485670089722}]}'\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "endpoint_name='wi-mlops-titanic-ml-train-piln-lr-endpoint'\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "sur_test_vector = [-1.4112866455793727,0.43135023895238417,2.006119339191895,1.89904574757844,2,1,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]\n",
    "nonsur_test_vector=[0.6692169576775447,-0.47519908120995513,-0.474325852103786,-0.3308153928167703,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "body = ','.join([str(item) for item in sur_test_vector])\n",
    "response = client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                               ContentType='text/csv',\n",
    "                               Body=body)\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a405cc",
   "metadata": {},
   "source": [
    "**Note:** Similarly you can change the test vector and can see how endpoint is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b596376",
   "metadata": {},
   "source": [
    "**References** <br/>\n",
    "- How to configure preprocessing jobs on step function (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateProcessingJob.html)\n",
    "- How to create batch transform jobs\n",
    "(https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTransformJob.html)\n",
    "- Create training jobs\n",
    "(https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)\n",
    "- In case if team wants to bring any sagemaker component\n",
    "(https://docs.aws.amazon.com/step-functions/latest/dg/connect-sagemaker.html)\n",
    "- How to create lambda using state function\n",
    "(https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-creating-lambda-state-machine.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47643d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up-- delete end point-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7857855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = boto3.client(\"sagemaker\", region_name=region)\n",
    "#response=client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
