{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2f3d68",
   "metadata": {},
   "source": [
    "# Push Data to respective S3 for Train Pipeline Trigger\n",
    "#what happens when we push this data to s3 ?\n",
    "#how it triggers the pipeline ?\n",
    "#Where this event is mapped and when it is defined?\n",
    "#what if my data source need to change?\n",
    "#will i get notification of the pipeline execution?\n",
    "#what if some steps fails in between- how to monitor and fix the issue?\n",
    "#what if we need to change pre processing logic?\n",
    "#what if model hyperparameter needs to be changed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47ff366f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 59.8 KiB/59.8 KiB (517.9 KiB/s) with 1 file(s) remaining\r",
      "upload: ../Notebooks_LatestCode/WiproFormat/train.csv to s3://wi-cred-datalake-dev-raw/titanic/input/data/train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp /home/ec2-user/SageMaker/WipCoe/Notebooks_LatestCode/WiproFormat/train.csv s3://wi-cred-datalake-dev-raw/titanic/input/data/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3db224",
   "metadata": {},
   "source": [
    "# Push data to trigger scoring\n",
    "#how the event is triggered ?\n",
    "#which version of model scoring file would refer ?\n",
    "#is there way to add additional attribute for better insight ?\n",
    "#are we linking the scoring file with the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7b2993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 76.2 KiB/76.2 KiB (786.2 KiB/s) with 1 file(s) remaining\r",
      "upload: ./scorewolabel.csv to s3://wi-cred-datalake-dev-raw/titanic/data/scoreinput/scorewolabel.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp scorewolabel.csv s3://wi-cred-datalake-dev-raw/titanic/data/scoreinput/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbecbc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook describes using the AWS Step Functions Data Science SDK to create and manage workflows. The Step Functions SDK is an open source library that allows data scientists to easily create and execute machine learning workflows using AWS Step Functions and Amazon SageMaker. For more information, see the following.\n",
    "* [AWS Step Functions](https://aws.amazon.com/step-functions/)\n",
    "* [AWS Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html)\n",
    "* [AWS Step Functions Data Science SDK](https://aws-step-functions-data-science-sdk.readthedocs.io)\n",
    "\n",
    "In this notebook we will use the SDK to create steps, link them together to create a workflow, and execute the workflow in AWS Step Functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40599882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install -qU awscli boto3 \"sagemaker>=2.0.0\"\n",
    "# !{sys.executable} -m pip install -qU \"stepfunctions>=2.0.0\"\n",
    "# !{sys.executable} -m pip show sagemaker stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f6571",
   "metadata": {},
   "source": [
    "## Prequisite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aea6f8",
   "metadata": {},
   "source": [
    "It is assumed that lambda functions for checking if model already exist or not and required IAM roles for Sagemaker, Step function is already created. <br/>\n",
    "In this notebook we are going to use Step Functions SDK build-up for Sagemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1866273",
   "metadata": {},
   "source": [
    "## 1. Preprocessing logic script\n",
    "\n",
    "Below is the preprocessing logic script which we will upload on S3 it will be used in preprocessing job. These scripts are the logic script which we have generated for preprocessing activities. Upload it on S3 and then we can use it as the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41714ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting titanic-preprocessing-linear-learner-script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile titanic-preprocessing-linear-learner-script.py\n",
    "# Importing required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "import glob\n",
    "# you can put any value here according to your situation\n",
    "chunksize = 10000\n",
    "from sklearn import preprocessing\n",
    "path = r'/opt/ml/processing/input' # Input path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "#all_files=[\"/home/ec2-user/SageMaker/WipCoe/Notebooks_LatestCode/WiproFormat/train.csv\"]\n",
    "#read them into pandas\n",
    "df_list = [pd.read_csv(filename) for filename in all_files]\n",
    "data = pd.concat(df_list)\n",
    "df = data.copy()\n",
    "#change this as per the data set\n",
    "#create all categorical variables that we did above for both training and test sets \n",
    "df['cabin_multiple'] = df.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n",
    "df['cabin_adv'] = df.Cabin.apply(lambda x: str(x)[0])\n",
    "df['numeric_ticket'] = df.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "df['ticket_letters'] = df.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\n",
    "df['name_title'] = df.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "#impute nulls for continuous data \n",
    "#df.Age = df.Age.fillna(training.Age.mean())\n",
    "df.Age = df.Age.fillna(df.Age.median())\n",
    "#df.Fare = df.Fare.fillna(training.Fare.mean())\n",
    "df.Fare = df.Fare.fillna(df.Fare.median())\n",
    "#drop null 'embarked' rows. Only 2 instances of this in training and 0 in test \n",
    "df.dropna(subset=['Embarked'],inplace = True)\n",
    "#tried log norm of sibsp (not used)\n",
    "df['norm_sibsp'] = np.log(df.SibSp+1)\n",
    "# log norm of fare (used)\n",
    "df['norm_fare'] = np.log(df.Fare+1)\n",
    "# converted fare to category for pd.get_dummies()\n",
    "df.Pclass = df.Pclass.astype(str)\n",
    "#created dummy variables from categories (also can use OneHotEncoder)\n",
    "all_dummies = pd.get_dummies(df[['PassengerId','Survived','Pclass','Sex','Age','SibSp','Parch','norm_fare','Embarked','cabin_adv','cabin_multiple','numeric_ticket','name_title']])\n",
    "#scaling\n",
    "encoded_df = all_dummies.copy()\n",
    "encoded_df[['Age','SibSp','Parch','norm_fare']]= scale.fit_transform(encoded_df[['Age','SibSp','Parch','norm_fare']])\n",
    "encoded_df\n",
    "#Split to train test again\n",
    "#split train test , change if diff split is requiredn\n",
    "train_data, validation_data, test_data = np.split(encoded_df.sample(frac=1, random_state=1729), [int(0.7 * len(encoded_df)), int(0.9*len(encoded_df))]) # Splitting dataset \n",
    "train_data=train_data.drop(columns=['PassengerId'])#id is used for ground truth, if there is no id column in data create custom and use that\n",
    "#workflow path\n",
    "train_data.to_csv('/opt/ml/processing/train/train.csv', index=False, header=False) # train data\n",
    "train_data.to_csv('/opt/ml/processing/trainbase/train_baseline.csv', index=False, header=True) # baseline data\n",
    "#local path\n",
    "# train_data.to_csv('titanic/train.csv', index=False, header=False) # xtrain data\n",
    "# train_data.to_csv('titanic/train_baseline.csv', index=False, header=True) # baseline data\n",
    "validbsline_data=validation_data.copy()\n",
    "validation_data=validation_data.drop(columns=['PassengerId'])#id is used for ground truth, if there is no id column in data create custom and use that\n",
    "validation_data.to_csv('/opt/ml/processing/validation/validation_data.csv', index=False, header=False) # validation data\n",
    "#validation_data.to_csv('titanic/validation_data.csv', index=False, header=False) # validation data\n",
    "validbsline= validbsline_data.drop(columns=['Survived']) # removing cloumn where we have to do predictions\n",
    "validbsline.to_csv('/opt/ml/processing/baselinemodeldrift/baselinemodeldrift.csv', index=False, header=False)\n",
    "#validbsline.to_csv('titanic/baselinemodeldrift.csv', index=False, header=False)\n",
    "#validation data without label---one set\n",
    "groundtrth=validbsline_data[['PassengerId','Survived']]#ground truth data should/only have Id,TargetVal colmun to corelate ground truth with predicted values \n",
    "groundtrth.to_csv('/opt/ml/processing/groundtruth/groundtruth.csv', index=False, header=True)\n",
    "#groundtrth.to_csv('titanic/groundtruth.csv', index=False, header=True)\n",
    "#ground truth (only label and ID)--2nd set\n",
    "test_data = test_data.iloc[:,1:] # removing cloumn where we have to do predictions\n",
    "test_data.to_csv('/opt/ml/processing/test/test.csv', index=False, header=False) # test data \n",
    "#test_data.to_csv('titanic/test.csv', index=False, header=False) # test data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71479c1a",
   "metadata": {},
   "source": [
    "## 2. Parameter\n",
    "\n",
    "Below are the list of paramters which we have to change inorder to run below sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90fabcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "v_workflow_execution_role = \"arn:aws:iam::525102048888:role/poc-sagemaker-step-functi-MachineLearningWorkflowE-1XFI2UPRXFTXE\" # Step function IAM role ARN\n",
    "v_preprocessing_iam_role = \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\" # IAM role for preprocessing container\n",
    "v_lambda_execution_role = \"arn:aws:iam::525102048888:role/poc-sagemaker-step-functi-LambaForDataGenerationEx-PKONGQTFWLRF\"\n",
    "v_preprocessing_instance_type = \"ml.m5.xlarge\" # Instance type for preprocessing container it changes as per workload\n",
    "v_s3_input_bucket = \"ds-mlops-dev\" # S3 bucket for input and output data\n",
    "v_prefix_for_input_data = \"titanic/data/input/inputdata.csv\"  # Prefix where data is stored\n",
    "v_prefix_for_code_location = \"titanic/code/titanic-preprocessing-linear-learner-script.py\" # prefix where code is stored\n",
    "v_lambda_function_name = \"ds-mlops-linear-learner-lambda-test\" # Name of lambda function for triggering training pipeline.\n",
    "v_region = 'us-east-1' # AWS region\n",
    "v_model_container = sagemaker.image_uris.retrieve('linear-learner', v_region) # Linear conatiner\n",
    "v_train_instance_type = \"ml.m5.xlarge\" # Instance type for training\n",
    "v_validation_scoring_instance_type = \"ml.m5.large\" # Instance type for batch scoring\n",
    "v_model_name = \"Titanic-linear-learner-02\" # Name of DS_MLOPS model to be kept\n",
    "# VV added after design review\n",
    "v_threshold=3000\n",
    "v_prefix_for_train_lambda=\"code/query_training_status.zip\"\n",
    "##\n",
    "# sec_groups = [\"sg-044e0e7ce4f5721c0\"]\n",
    "# subnets = [\"subnet-0cf0e3f46326aa259\",\n",
    "#            \"subnet-0156b7f5500cf0b78\",\n",
    "#            \"subnet-032420199163cff9b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e2fa3",
   "metadata": {},
   "source": [
    "## 3 Import the required modules from the SDK and uploading code to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0b2b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepfunctions\n",
    "import logging\n",
    "\n",
    "from stepfunctions.steps import *\n",
    "from stepfunctions.workflow import Workflow\n",
    "from stepfunctions import steps\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from sagemaker.processing import Processor,ProcessingInput, ProcessingOutput\n",
    "import uuid\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import boto3\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "stepfunctions.set_stream_logger(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a251a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 4.2 KiB/4.2 KiB (56.4 KiB/s) with 1 file(s) remaining\r",
      "upload: ./titanic-preprocessing-linear-learner-script.py to s3://ds-mlops-dev/titanic/code/titanic-preprocessing-linear-learner-script.py\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp titanic-preprocessing-linear-learner-script.py s3://$v_s3_input_bucket/$v_prefix_for_code_location # Uploading preprocessing code on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e86cb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp titanic-preprocessing-linear-learner-script.py /home/ec2-user/SageMaker/WipCoe/VW-TitanicDeployment/train_preprocessing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2bd6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp titanic-preprocessing-linear-learner-script.py /home/ec2-user/SageMaker/WipCoe/VW-TitanicDeployment/train_preprocessing/titanic-preprocessing-xgb-script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c537cc8",
   "metadata": {},
   "source": [
    "#added below lambda for query training status to read metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08588409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query_training_status.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile query_training_status.py\n",
    "import boto3\n",
    "import logging\n",
    "import json\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "#Retrieve transform job name from event and return transform job status.\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    if ('TrainingJobName' in event):\n",
    "        job_name = event['TrainingJobName']\n",
    "\n",
    "    else:\n",
    "        raise KeyError('TrainingJobName key not found in function input!'+\n",
    "                      ' The input received was: {}.'.format(json.dumps(event)))\n",
    "\n",
    "    #Query boto3 API to check training status.\n",
    "    try:\n",
    "        response = sm_client.describe_training_job(TrainingJobName=job_name)\n",
    "        logger.info(\"Training job:{} has status:{}.\".format(job_name,\n",
    "            response['TrainingJobStatus']))\n",
    "\n",
    "    except Exception as e:\n",
    "        response = ('Failed to read training status!'+ \n",
    "                    ' The training job may not exist or the job name may be incorrect.'+ \n",
    "                    ' Check SageMaker to confirm the job name.')\n",
    "        print(e)\n",
    "        print('{} Attempted to read job name: {}.'.format(response, job_name))\n",
    "\n",
    "    #We can't marshall datetime objects in JSON response. So convert\n",
    "    #all datetime objects returned to unix time.\n",
    "    for index, metric in enumerate(response['FinalMetricDataList']):\n",
    "        metric['Timestamp'] = metric['Timestamp'].timestamp()\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'trainingMetrics': response['FinalMetricDataList']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8576afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: query_training_status.py (deflated 55%)\r\n"
     ]
    }
   ],
   "source": [
    "## VV added after review\n",
    "! zip query_training_status.zip query_training_status.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f540d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 846 Bytes/846 Bytes (9.0 KiB/s) with 1 file(s) remaining\r",
      "upload: ./query_training_status.zip to s3://ds-mlops-dev/code/query_training_status.zip\r\n"
     ]
    }
   ],
   "source": [
    "## VV added after review\n",
    "! aws s3 cp query_training_status.zip s3://$v_s3_input_bucket/$v_prefix_for_train_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a39093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n"
     ]
    }
   ],
   "source": [
    "## VV added after review\n",
    "function_name = 'LinearLearnerQuery-training-status'\n",
    "try:\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    response = lambda_client.create_function(\n",
    "        FunctionName=function_name,\n",
    "        Runtime='python3.7',\n",
    "        Role=v_lambda_execution_role,\n",
    "        Handler='query_training_status.lambda_handler',\n",
    "        Code={\n",
    "            'S3Bucket':v_s3_input_bucket,\n",
    "            'S3Key': '{}'.format(v_s3_input_bucket)\n",
    "        },\n",
    "        Description='Queries a SageMaker training job and return the results.',\n",
    "        Timeout=15,\n",
    "        MemorySize=128\n",
    "    )\n",
    "except:\n",
    "    print(\"exception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e53c43",
   "metadata": {},
   "source": [
    "## 4. Create workflow\n",
    "\n",
    "In the following cell, you will define the step that you will use in our first workflow.  Then you will create, visualize and execute the workflow. \n",
    "\n",
    "Steps relate to states in AWS Step Functions. For more information, see [States](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-states.html) in the *AWS Step Functions Developer Guide*. For more information on the AWS Step Functions Data Science SDK APIs, see: https://aws-step-functions-data-science-sdk.readthedocs.io. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b93057",
   "metadata": {},
   "source": [
    "## 4.1 Creating Pre-Processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff365eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"s3://{}/{}\".format(v_s3_input_bucket,v_prefix_for_input_data)\n",
    "input_code = \"s3://{}/{}\".format(v_s3_input_bucket,v_prefix_for_code_location)\n",
    "output_data = \"s3://{}/{}\".format(v_s3_input_bucket,\"titanic/preprocess-data\")\n",
    "\n",
    "inputs = [\n",
    "    ProcessingInput(\n",
    "        source=input_data, destination=\"/opt/ml/processing/input\", input_name=\"input\"\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=input_code,\n",
    "        destination=\"/opt/ml/processing/input/code\",\n",
    "        input_name=\"code\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/train\",\n",
    "        destination=\"{}/{}\".format(output_data,\"train\"),\n",
    "        output_name=\"train_data\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/test\",\n",
    "        destination=\"{}/{}\".format(output_data, \"test\"),\n",
    "        output_name=\"test_data\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/validation\",\n",
    "        destination=\"{}/{}\".format(output_data, \"validation\"),\n",
    "        output_name=\"validation_data\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/baselinemodeldrift\",\n",
    "        destination=\"{}/{}\".format(output_data,\"baselinemodeldrift\"),\n",
    "        output_name=\"baselinemodeldrift\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/groundtruth\",\n",
    "        destination=\"{}/{}\".format(output_data,\"groundtruth\"),\n",
    "        output_name=\"groundtruth\",\n",
    "    ),\n",
    "    \n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/trainbase\",\n",
    "        destination=\"{}/{}\".format(output_data,\"trainbase\"),\n",
    "        output_name=\"trainbase\",\n",
    "    )   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4173bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://ds-mlops-dev/titanic/data/input/inputdata.csv\n"
     ]
    }
   ],
   "source": [
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ad890cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique names for Pre-Processing Job, Training Job, and Model Evaluation Job for the Step Functions Workflow\n",
    "training_job_name = \"Titanic-ll-training-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Training Job requires a unique name\n",
    "preprocessing_job_name = \"Titanic-ll-preprocessing-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Preprocessing job requires a unique name,\n",
    "evaluation_job_name = \"Titanic-ll-evaluation-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Evaluation Job requires a unique name\n",
    "scoring_job_name = \"Titanic-ll-score-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Evaluation Job requires a unique name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53dd2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker expects unique names for each job, model and endpoint.\n",
    "# If these names are not unique the execution will fail. Pass these dynamically for each execution using placeholders.\n",
    "\n",
    "##VV updated after review\n",
    "\n",
    "execution_input = ExecutionInput(\n",
    "    schema={\n",
    "        \"PreprocessingJobName\": str,\n",
    "        \"TrainingJobName\": str,\n",
    "        \"EvaluationProcessingJobName\": str,\n",
    "        \"ModelName\": str,\n",
    "        \"EndPointConfig\":str,\n",
    "        \"EndpointName\":str,\n",
    "        \"ScoreJobName\":str\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39afa110",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor =Processor(image_uri='683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3',\n",
    "                     role=v_preprocessing_iam_role,\n",
    "                     instance_count=1,\n",
    "                     instance_type=v_preprocessing_instance_type\n",
    "                    #network_config = NetworkConfig(security_group_ids = sec_groups, subnets = subnets)\n",
    "                     )\n",
    "#processor.JOB_CLASS_NAME= 'processing-job'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5a823fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique names for Pre-Processing Job, Training Job, and Model Evaluation Job for the Step Functions Workflow\n",
    "training_job_name = \"Titanic-ll-training-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Training Job requires a unique name\n",
    "preprocessing_job_name = \"Titanic-ll--preprocessing-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Preprocessing job requires a unique name,\n",
    "evaluation_job_name = \"Titanic-ll--evaluation-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Evaluation Job requires a unique name\n",
    "scoring_job_name = \"Titanic-ll-score-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Evaluation Job requires a unique name\n",
    "endpoint_name = \"Titanic-endpoint-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Evaluation Job requires a unique name\n",
    "endpoint_config_name = \"Titanic-endpoint-config-{}\".format(\n",
    "    uuid.uuid1().hex\n",
    ")  # Each Evaluation Job requires a unique name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eaec9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processor.JOB_CLASS_NAME= 'processing-job'\n",
    "preprocessing_step = ProcessingStep(\n",
    "    state_id='Pre-processing', \n",
    "    processor=processor,\n",
    "    #JOB_CLASS_NAME='processing_job',\n",
    "    job_name=preprocessing_job_name, \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    experiment_config=None, \n",
    "    container_entrypoint=[\"python3\", \"/opt/ml/processing/input/code/titanic-preprocessing-linear-learner-script.py\"], # DS needs to change this directory /path\n",
    "    wait_for_completion=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290e2c2",
   "metadata": {},
   "source": [
    "## 4.2 Train trigger lambda function (Check if model with same name exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33111db1",
   "metadata": {},
   "source": [
    "In the following cell, we define a lambda step that will invoke the previously created lambda function as part of our Step Function workflow. See [LambdaStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/compute.html#stepfunctions.steps.compute.LambdaStep) in the AWS Step Functions Data Science SDK documentation to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77e76382",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker') # getting sagemaker client \n",
    "try:\n",
    "    client.delete_model(\n",
    "        ModelName=v_model_name # delete if some model exist with this name\n",
    "    )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9e1b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_step = compute.LambdaStep(\n",
    "    'Start Training',\n",
    "    parameters={  \n",
    "        \"FunctionName\": v_lambda_function_name\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ba89661",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VV added after review\n",
    "lambda_step_acc = compute.LambdaStep(\n",
    "    'Query Training Results',\n",
    "    parameters={  \n",
    "        \"FunctionName\": function_name,\n",
    "        'Payload':{\n",
    "            \"TrainingJobName.$\": '$.TrainingJobName'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afd5812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VV added after review\n",
    "check_accuracy_step = steps.states.Choice(\n",
    "    'RMSE < Threshold'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2afc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VV added after review\n",
    "fail_step = steps.states.Fail(\n",
    "    'Model Accuracy Too Low',\n",
    "    comment='Validation accuracy lower than threshold'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f8179",
   "metadata": {},
   "source": [
    "## 4.3 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65424a2",
   "metadata": {},
   "source": [
    "### Create a SageMaker Training Step \n",
    "\n",
    "In the following cell, we create the training step and pass the estimator we defined above. See  [TrainingStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/sagemaker.html#stepfunctions.steps.sagemaker.TrainingStep) in the AWS Step Functions Data Science SDK documentation to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de9bc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "training_output = 's3://{}/models'.format(v_s3_input_bucket) # model output locations\n",
    "linear = sagemaker.estimator.Estimator(v_model_container,\n",
    "                                       v_preprocessing_iam_role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m5.xlarge',\n",
    "                                       output_path=training_output,\n",
    "                                       sagemaker_session = sess,\n",
    "                                      #security_group_ids=sec_groups,\n",
    "                                       #subnets=subnets\n",
    "                                      )\n",
    "\n",
    "linear.set_hyperparameters(epochs = 50,\n",
    "                           l1 = 0.0014121036264995773,\n",
    "                           learning_rate = 0.012104062065442999,\n",
    "                           mini_batch_size = 256,\n",
    "                           predictor_type = \"regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cde35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = TrainingStep(\n",
    "    'Model Training(linear)', \n",
    "    estimator=linear,\n",
    "    data={\n",
    "        'train': TrainingInput(\"{}/{}/\".format(output_data,\"train\"), content_type='text/csv'),\n",
    "        'validation': TrainingInput(\"{}/{}/\".format(output_data, \"validation\"), content_type='text/csv')\n",
    "    },\n",
    "    job_name=execution_input['TrainingJobName'],\n",
    "    wait_for_completion=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a2edff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://ds-mlops-dev/titanic/preprocess-data\n"
     ]
    }
   ],
   "source": [
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf188e2f",
   "metadata": {},
   "source": [
    "## 4.4 Create a Model\n",
    "\n",
    "In the following cell, we define a model step that will create a model in Amazon SageMaker using the artifacts created during the TrainingStep. See  [ModelStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/sagemaker.html#stepfunctions.steps.sagemaker.ModelStep) in the AWS Step Functions Data Science SDK documentation to learn more.\n",
    "\n",
    "The model creation step typically follows the training step. The Step Functions SDK provides the [get_expected_model](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/sagemaker.html#stepfunctions.steps.sagemaker.TrainingStep.get_expected_model) method in the TrainingStep class to provide a reference for the trained model artifacts. Please note that this method is only useful when the ModelStep directly follows the TrainingStep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "566d1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_step = ModelStep(\n",
    "    'Save Model',\n",
    "    model=training_step.get_expected_model(),\n",
    "    model_name=execution_input['ModelName'],\n",
    "    result_path='$.ModelStepResults'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da63755",
   "metadata": {},
   "source": [
    "## 4.5 Create a batch transform step\n",
    "\n",
    "Now once all the above steps are done we will perform scoring on a small data set to see all the components are working fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4c7916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "\n",
    "batch_scoring = TransformStep(\n",
    "    state_id=\"validation-step\",\n",
    "    job_name=execution_input['ScoreJobName'],\n",
    "    transformer=linear.transformer(instance_count=1,\n",
    "                                instance_type=v_validation_scoring_instance_type),\n",
    "    data=\"{}/{}\".format(output_data, \"test\"), # location for test data\n",
    "    model_name=execution_input['ModelName'],\n",
    "    content_type=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c94f03",
   "metadata": {},
   "source": [
    "# Create End point config and end point step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "890ede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VV added after review\n",
    "endpoint_config_step = steps.EndpointConfigStep(\n",
    "    \"Create Model Endpoint Config\",\n",
    "    endpoint_config_name=execution_input['EndPointConfig'],\n",
    "    model_name=execution_input['ModelName'],\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6e2c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VV added after review\n",
    "endpoint_step = steps.EndpointStep(\n",
    "    'Update Model Endpoint',\n",
    "    endpoint_name=execution_input['EndpointName'],\n",
    "    endpoint_config_name=execution_input['EndPointConfig'],\n",
    "    update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5c2f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VV added after review\n",
    "threshold_rule = steps.choice_rule.ChoiceRule.NumericLessThan(variable=lambda_step.output()['Payload']['trainingMetrics'][0]['Value'], value=v_threshold)\n",
    "check_accuracy_step.add_choice(rule=threshold_rule, next_step=endpoint_config_step)\n",
    "check_accuracy_step.default_choice(next_step=fail_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45ccf616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Update Model Endpoint EndpointStep(resource='arn:aws:states:::sagemaker:createEndpoint', parameters={'EndpointConfigName': <stepfunctions.inputs.placeholders.ExecutionInput object at 0x7f81b3e63160>, 'EndpointName': <stepfunctions.inputs.placeholders.ExecutionInput object at 0x7f81b3e63198>}, type='Task')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##VV added after review\n",
    "endpoint_config_step.next(endpoint_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d620447",
   "metadata": {},
   "source": [
    "## 4.6 Chain together steps for the basic path\n",
    "\n",
    "The following cell links together the steps you've created into a sequential group called `basic_path`. We will chain a single step to create our basic path. See [Chain](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/states.html#stepfunctions.steps.states.Chain) in the AWS Step Functions Data Science SDK documentation.\n",
    "\n",
    "After chaining together the steps for the basic path, in this case only one step, we will visualize the basic path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "495dc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First we chain the start pass state,preprocessing_step,\n",
    "basic_path=Chain([preprocessing_step,\n",
    "                  training_step,\n",
    "                  model_step,\n",
    "                  lambda_step_acc,\n",
    "                  check_accuracy_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75ddf3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First we chain the start pass state,preprocessing_step,\n",
    "# basic_path=Chain([training_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554c292",
   "metadata": {},
   "source": [
    "## 4.7 Define the workflow instance\n",
    "\n",
    "The following cell defines the [workflow](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow) with the path we just defined.\n",
    "\n",
    "After defining the workflow, we will render the graph to see what our workflow looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cfe18b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-186\" class=\"workflowgraph\">\n",
       "    \n",
       "    <svg></svg>\n",
       "    \n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-186')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 600,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Pre-processing\", \"States\": {\"Pre-processing\": {\"Resource\": \"arn:aws:states:::sagemaker:createProcessingJob.sync\", \"Parameters\": {\"ProcessingJobName\": \"Titanic-ll--preprocessing-73cec0161a0611ed8cef065a32dff597\", \"ProcessingInputs\": [{\"InputName\": \"input\", \"AppManaged\": false, \"S3Input\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/data/input/inputdata.csv\", \"LocalPath\": \"/opt/ml/processing/input\", \"S3DataType\": \"S3Prefix\", \"S3InputMode\": \"File\", \"S3DataDistributionType\": \"FullyReplicated\", \"S3CompressionType\": \"None\"}}, {\"InputName\": \"code\", \"AppManaged\": false, \"S3Input\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/code/titanic-preprocessing-linear-learner-script.py\", \"LocalPath\": \"/opt/ml/processing/input/code\", \"S3DataType\": \"S3Prefix\", \"S3InputMode\": \"File\", \"S3DataDistributionType\": \"FullyReplicated\", \"S3CompressionType\": \"None\"}}], \"ProcessingOutputConfig\": {\"Outputs\": [{\"OutputName\": \"train_data\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/train\", \"LocalPath\": \"/opt/ml/processing/train\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"test_data\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/test\", \"LocalPath\": \"/opt/ml/processing/test\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"validation_data\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/validation\", \"LocalPath\": \"/opt/ml/processing/validation\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"baselinemodeldrift\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/baselinemodeldrift\", \"LocalPath\": \"/opt/ml/processing/baselinemodeldrift\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"groundtruth\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/groundtruth\", \"LocalPath\": \"/opt/ml/processing/groundtruth\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"trainbase\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/trainbase\", \"LocalPath\": \"/opt/ml/processing/trainbase\", \"S3UploadMode\": \"EndOfJob\"}}]}, \"AppSpecification\": {\"ImageUri\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\", \"ContainerEntrypoint\": [\"python3\", \"/opt/ml/processing/input/code/titanic-preprocessing-linear-learner-script.py\"]}, \"RoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\", \"ProcessingResources\": {\"ClusterConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.xlarge\", \"VolumeSizeInGB\": 30}}}, \"Type\": \"Task\", \"Next\": \"Model Training(linear)\"}, \"Model Training(linear)\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification\": {\"TrainingImage\": \"382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\", \"TrainingInputMode\": \"File\"}, \"OutputDataConfig\": {\"S3OutputPath\": \"s3://ds-mlops-dev/models\"}, \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 86400}, \"ResourceConfig\": {\"VolumeSizeInGB\": 30, \"InstanceCount\": 1, \"InstanceType\": \"ml.m5.xlarge\"}, \"RoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\", \"InputDataConfig\": [{\"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/train/\", \"S3DataDistributionType\": \"FullyReplicated\"}}, \"ContentType\": \"text/csv\", \"ChannelName\": \"train\"}, {\"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/validation/\", \"S3DataDistributionType\": \"FullyReplicated\"}}, \"ContentType\": \"text/csv\", \"ChannelName\": \"validation\"}], \"HyperParameters\": {\"epochs\": \"50\", \"l1\": \"0.0014121036264995773\", \"learning_rate\": \"0.012104062065442999\", \"mini_batch_size\": \"256\", \"predictor_type\": \"regressor\"}, \"TrainingJobName.$\": \"$$.Execution.Input['TrainingJobName']\"}, \"Type\": \"Task\", \"Next\": \"Save Model\"}, \"Save Model\": {\"ResultPath\": \"$.ModelStepResults\", \"Parameters\": {\"ExecutionRoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\", \"ModelName.$\": \"$$.Execution.Input['ModelName']\", \"PrimaryContainer\": {\"Environment\": {}, \"Image\": \"382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\", \"ModelDataUrl.$\": \"$['ModelArtifacts']['S3ModelArtifacts']\"}}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Query Training Results\"}, \"Query Training Results\": {\"Parameters\": {\"FunctionName\": \"LinearLearnerQuery-training-status\", \"Payload\": {\"TrainingJobName.$\": \"$.TrainingJobName\"}}, \"Resource\": \"arn:aws:states:::lambda:invoke\", \"Type\": \"Task\", \"Next\": \"RMSE < Threshold\"}, \"RMSE < Threshold\": {\"Type\": \"Choice\", \"Choices\": [{\"Variable\": \"$['Payload']['trainingMetrics'][0]['Value']\", \"NumericLessThan\": 3000, \"Next\": \"Create Model Endpoint Config\"}], \"Default\": \"Model Accuracy Too Low\"}, \"Model Accuracy Too Low\": {\"Comment\": \"Validation accuracy lower than threshold\", \"Type\": \"Fail\"}, \"Create Model Endpoint Config\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['EndPointConfig']\", \"ProductionVariants\": [{\"InitialInstanceCount\": 1, \"InstanceType\": \"ml.m4.xlarge\", \"ModelName.$\": \"$$.Execution.Input['ModelName']\", \"VariantName\": \"AllTraffic\"}]}, \"Type\": \"Task\", \"Next\": \"Update Model Endpoint\"}, \"Update Model Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['EndPointConfig']\", \"EndpointName.$\": \"$$.Execution.Input['EndpointName']\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-186';\n",
       "\n",
       "    var graph = new sfn.StateMachineGraph(definition, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we define the workflow\n",
    "basic_workflow = Workflow(\n",
    "    name=\"Titanic-linear-learner-step-function\",\n",
    "    definition=basic_path,\n",
    "    role=v_workflow_execution_role\n",
    ")\n",
    "\n",
    "#Render the workflow\n",
    "basic_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e3848",
   "metadata": {},
   "source": [
    "## 4.8 Review the Amazon States Language code for your workflow\n",
    "\n",
    "The following renders the JSON of the [Amazon States Language](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html) definition of the workflow you created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35bf23a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"StartAt\": \"Pre-processing\",\n",
      "    \"States\": {\n",
      "        \"Pre-processing\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createProcessingJob.sync\",\n",
      "            \"Parameters\": {\n",
      "                \"ProcessingJobName\": \"Titanic-ll--preprocessing-73cec0161a0611ed8cef065a32dff597\",\n",
      "                \"ProcessingInputs\": [\n",
      "                    {\n",
      "                        \"InputName\": \"input\",\n",
      "                        \"AppManaged\": false,\n",
      "                        \"S3Input\": {\n",
      "                            \"S3Uri\": \"s3://ds-mlops-dev/titanic/data/input/inputdata.csv\",\n",
      "                            \"LocalPath\": \"/opt/ml/processing/input\",\n",
      "                            \"S3DataType\": \"S3Prefix\",\n",
      "                            \"S3InputMode\": \"File\",\n",
      "                            \"S3DataDistributionType\": \"FullyReplicated\",\n",
      "                            \"S3CompressionType\": \"None\"\n",
      "                        }\n",
      "                    },\n",
      "                    {\n",
      "                        \"InputName\": \"code\",\n",
      "                        \"AppManaged\": false,\n",
      "                        \"S3Input\": {\n",
      "                            \"S3Uri\": \"s3://ds-mlops-dev/titanic/code/titanic-preprocessing-linear-learner-script.py\",\n",
      "                            \"LocalPath\": \"/opt/ml/processing/input/code\",\n",
      "                            \"S3DataType\": \"S3Prefix\",\n",
      "                            \"S3InputMode\": \"File\",\n",
      "                            \"S3DataDistributionType\": \"FullyReplicated\",\n",
      "                            \"S3CompressionType\": \"None\"\n",
      "                        }\n",
      "                    }\n",
      "                ],\n",
      "                \"ProcessingOutputConfig\": {\n",
      "                    \"Outputs\": [\n",
      "                        {\n",
      "                            \"OutputName\": \"train_data\",\n",
      "                            \"AppManaged\": false,\n",
      "                            \"S3Output\": {\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/train\",\n",
      "                                \"LocalPath\": \"/opt/ml/processing/train\",\n",
      "                                \"S3UploadMode\": \"EndOfJob\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"OutputName\": \"test_data\",\n",
      "                            \"AppManaged\": false,\n",
      "                            \"S3Output\": {\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/test\",\n",
      "                                \"LocalPath\": \"/opt/ml/processing/test\",\n",
      "                                \"S3UploadMode\": \"EndOfJob\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"OutputName\": \"validation_data\",\n",
      "                            \"AppManaged\": false,\n",
      "                            \"S3Output\": {\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/validation\",\n",
      "                                \"LocalPath\": \"/opt/ml/processing/validation\",\n",
      "                                \"S3UploadMode\": \"EndOfJob\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"OutputName\": \"baselinemodeldrift\",\n",
      "                            \"AppManaged\": false,\n",
      "                            \"S3Output\": {\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/baselinemodeldrift\",\n",
      "                                \"LocalPath\": \"/opt/ml/processing/baselinemodeldrift\",\n",
      "                                \"S3UploadMode\": \"EndOfJob\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"OutputName\": \"groundtruth\",\n",
      "                            \"AppManaged\": false,\n",
      "                            \"S3Output\": {\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/groundtruth\",\n",
      "                                \"LocalPath\": \"/opt/ml/processing/groundtruth\",\n",
      "                                \"S3UploadMode\": \"EndOfJob\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"OutputName\": \"trainbase\",\n",
      "                            \"AppManaged\": false,\n",
      "                            \"S3Output\": {\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/trainbase\",\n",
      "                                \"LocalPath\": \"/opt/ml/processing/trainbase\",\n",
      "                                \"S3UploadMode\": \"EndOfJob\"\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                \"AppSpecification\": {\n",
      "                    \"ImageUri\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\",\n",
      "                    \"ContainerEntrypoint\": [\n",
      "                        \"python3\",\n",
      "                        \"/opt/ml/processing/input/code/titanic-preprocessing-linear-learner-script.py\"\n",
      "                    ]\n",
      "                },\n",
      "                \"RoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\",\n",
      "                \"ProcessingResources\": {\n",
      "                    \"ClusterConfig\": {\n",
      "                        \"InstanceCount\": 1,\n",
      "                        \"InstanceType\": \"ml.m5.xlarge\",\n",
      "                        \"VolumeSizeInGB\": 30\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Model Training(linear)\"\n",
      "        },\n",
      "        \"Model Training(linear)\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n",
      "            \"Parameters\": {\n",
      "                \"AlgorithmSpecification\": {\n",
      "                    \"TrainingImage\": \"382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\",\n",
      "                    \"TrainingInputMode\": \"File\"\n",
      "                },\n",
      "                \"OutputDataConfig\": {\n",
      "                    \"S3OutputPath\": \"s3://ds-mlops-dev/models\"\n",
      "                },\n",
      "                \"StoppingCondition\": {\n",
      "                    \"MaxRuntimeInSeconds\": 86400\n",
      "                },\n",
      "                \"ResourceConfig\": {\n",
      "                    \"VolumeSizeInGB\": 30,\n",
      "                    \"InstanceCount\": 1,\n",
      "                    \"InstanceType\": \"ml.m5.xlarge\"\n",
      "                },\n",
      "                \"RoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\",\n",
      "                \"InputDataConfig\": [\n",
      "                    {\n",
      "                        \"DataSource\": {\n",
      "                            \"S3DataSource\": {\n",
      "                                \"S3DataType\": \"S3Prefix\",\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/train/\",\n",
      "                                \"S3DataDistributionType\": \"FullyReplicated\"\n",
      "                            }\n",
      "                        },\n",
      "                        \"ContentType\": \"text/csv\",\n",
      "                        \"ChannelName\": \"train\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"DataSource\": {\n",
      "                            \"S3DataSource\": {\n",
      "                                \"S3DataType\": \"S3Prefix\",\n",
      "                                \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/validation/\",\n",
      "                                \"S3DataDistributionType\": \"FullyReplicated\"\n",
      "                            }\n",
      "                        },\n",
      "                        \"ContentType\": \"text/csv\",\n",
      "                        \"ChannelName\": \"validation\"\n",
      "                    }\n",
      "                ],\n",
      "                \"HyperParameters\": {\n",
      "                    \"epochs\": \"50\",\n",
      "                    \"l1\": \"0.0014121036264995773\",\n",
      "                    \"learning_rate\": \"0.012104062065442999\",\n",
      "                    \"mini_batch_size\": \"256\",\n",
      "                    \"predictor_type\": \"regressor\"\n",
      "                },\n",
      "                \"TrainingJobName.$\": \"$$.Execution.Input['TrainingJobName']\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Save Model\"\n",
      "        },\n",
      "        \"Save Model\": {\n",
      "            \"ResultPath\": \"$.ModelStepResults\",\n",
      "            \"Parameters\": {\n",
      "                \"ExecutionRoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\",\n",
      "                \"ModelName.$\": \"$$.Execution.Input['ModelName']\",\n",
      "                \"PrimaryContainer\": {\n",
      "                    \"Environment\": {},\n",
      "                    \"Image\": \"382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\",\n",
      "                    \"ModelDataUrl.$\": \"$['ModelArtifacts']['S3ModelArtifacts']\"\n",
      "                }\n",
      "            },\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Query Training Results\"\n",
      "        },\n",
      "        \"Query Training Results\": {\n",
      "            \"Parameters\": {\n",
      "                \"FunctionName\": \"LinearLearnerQuery-training-status\",\n",
      "                \"Payload\": {\n",
      "                    \"TrainingJobName.$\": \"$.TrainingJobName\"\n",
      "                }\n",
      "            },\n",
      "            \"Resource\": \"arn:aws:states:::lambda:invoke\",\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"RMSE < Threshold\"\n",
      "        },\n",
      "        \"RMSE < Threshold\": {\n",
      "            \"Type\": \"Choice\",\n",
      "            \"Choices\": [\n",
      "                {\n",
      "                    \"Variable\": \"$['Payload']['trainingMetrics'][0]['Value']\",\n",
      "                    \"NumericLessThan\": 3000,\n",
      "                    \"Next\": \"Create Model Endpoint Config\"\n",
      "                }\n",
      "            ],\n",
      "            \"Default\": \"Model Accuracy Too Low\"\n",
      "        },\n",
      "        \"Model Accuracy Too Low\": {\n",
      "            \"Comment\": \"Validation accuracy lower than threshold\",\n",
      "            \"Type\": \"Fail\"\n",
      "        },\n",
      "        \"Create Model Endpoint Config\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['EndPointConfig']\",\n",
      "                \"ProductionVariants\": [\n",
      "                    {\n",
      "                        \"InitialInstanceCount\": 1,\n",
      "                        \"InstanceType\": \"ml.m4.xlarge\",\n",
      "                        \"ModelName.$\": \"$$.Execution.Input['ModelName']\",\n",
      "                        \"VariantName\": \"AllTraffic\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Update Model Endpoint\"\n",
      "        },\n",
      "        \"Update Model Endpoint\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['EndPointConfig']\",\n",
      "                \"EndpointName.$\": \"$$.Execution.Input['EndpointName']\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"End\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(basic_workflow.definition.to_json(pretty=True)) # From this json we would be leveraging the codes to create the Cloud Formation parameterized template..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e277fb3",
   "metadata": {},
   "source": [
    "## 4.9 Create the workflow on AWS Step Functions\n",
    "\n",
    "Create the workflow in AWS Step Functions with [create](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c0e9d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[ERROR] A workflow with the same name already exists on AWS Step Functions. To update a workflow, use Workflow.update().\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arn:aws:states:us-east-1:525102048888:stateMachine:Titanic-linear-learner-step-function'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8bf56df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] Workflow updated successfully on AWS Step Functions. All execute() calls will use the updated definition and role within a few seconds. \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arn:aws:states:us-east-1:525102048888:stateMachine:Titanic-linear-learner-step-function'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_workflow.update(definition=basic_workflow.definition,role=basic_workflow.role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd6683",
   "metadata": {},
   "source": [
    "## 5 Execute the workflow\n",
    "\n",
    "Run the workflow with [execute](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.execute). Since the workflow only has a pass state, it will succeed immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2763bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] Workflow execution started successfully on AWS Step Functions.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "basic_workflow_execution = basic_workflow.execute(\n",
    "    inputs={\n",
    "        \"PreprocessingJobName\": preprocessing_job_name,  # Each pre processing job (SageMaker processing job) requires a unique name,\n",
    "        \"TrainingJobName\": training_job_name,  # Each Sagemaker Training job requires a unique name,\n",
    "        \"EvaluationProcessingJobName\": evaluation_job_name,  # Each SageMaker processing job requires a unique name,\n",
    "        \"ModelName\" : v_model_name, # Name of model ,\n",
    "        \"ScoreJobName\" : scoring_job_name,\n",
    "        \"EndpointName\" : endpoint_name,\n",
    "        \"EndPointConfig\" : endpoint_config_name\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c2bd6",
   "metadata": {},
   "source": [
    "## 5.1 Review the execution progress\n",
    "\n",
    "Render workflow progress with the [render_progress](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Execution.render_progress).\n",
    "\n",
    "This generates a snapshot of the current state of your workflow as it executes. This is a static image. Run the cell again to check progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da8c49ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-124\" class=\"workflowgraph\">\n",
       "    \n",
       "    <style>\n",
       "        .graph-legend ul {\n",
       "            list-style-type: none;\n",
       "            padding: 10px;\n",
       "            padding-left: 0;\n",
       "            margin: 0;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            background: transparent;\n",
       "        }\n",
       "\n",
       "        .graph-legend li {\n",
       "            margin-left: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend li > div {\n",
       "            width: 10px;\n",
       "            height: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend .success { background-color: #2BD62E }\n",
       "        .graph-legend .failed { background-color: #DE322F }\n",
       "        .graph-legend .cancelled { background-color: #DDDDDD }\n",
       "        .graph-legend .in-progress { background-color: #53C9ED }\n",
       "        .graph-legend .caught-error { background-color: #FFA500 }\n",
       "    </style>\n",
       "    <div class=\"graph-legend\">\n",
       "        <ul>\n",
       "            <li>\n",
       "                <div class=\"success\"></div>\n",
       "                <span>Success</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"failed\"></div>\n",
       "                <span>Failed</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"cancelled\"></div>\n",
       "                <span>Cancelled</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"in-progress\"></div>\n",
       "                <span>In Progress</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"caught-error\"></div>\n",
       "                <span>Caught Error</span>\n",
       "            </li>\n",
       "        </ul>\n",
       "    </div>\n",
       "\n",
       "    <svg></svg>\n",
       "    <a href=\"https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:525102048888:execution:Titanic-linear-learner-step-function:0e5c997e-871a-4f04-abce-7996d1a006fc\" target=\"_blank\"> Inspect in AWS Step Functions </a>\n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-124')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 1000,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Pre-processing\", \"States\": {\"Pre-processing\": {\"Resource\": \"arn:aws:states:::sagemaker:createProcessingJob.sync\", \"Parameters\": {\"ProcessingJobName\": \"Titanic-ll--preprocessing-73cec0161a0611ed8cef065a32dff597\", \"ProcessingInputs\": [{\"InputName\": \"input\", \"AppManaged\": false, \"S3Input\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/data/input/inputdata.csv\", \"LocalPath\": \"/opt/ml/processing/input\", \"S3DataType\": \"S3Prefix\", \"S3InputMode\": \"File\", \"S3DataDistributionType\": \"FullyReplicated\", \"S3CompressionType\": \"None\"}}, {\"InputName\": \"code\", \"AppManaged\": false, \"S3Input\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/code/titanic-preprocessing-linear-learner-script.py\", \"LocalPath\": \"/opt/ml/processing/input/code\", \"S3DataType\": \"S3Prefix\", \"S3InputMode\": \"File\", \"S3DataDistributionType\": \"FullyReplicated\", \"S3CompressionType\": \"None\"}}], \"ProcessingOutputConfig\": {\"Outputs\": [{\"OutputName\": \"train_data\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/train\", \"LocalPath\": \"/opt/ml/processing/train\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"test_data\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/test\", \"LocalPath\": \"/opt/ml/processing/test\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"validation_data\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/validation\", \"LocalPath\": \"/opt/ml/processing/validation\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"baselinemodeldrift\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/baselinemodeldrift\", \"LocalPath\": \"/opt/ml/processing/baselinemodeldrift\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"groundtruth\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/groundtruth\", \"LocalPath\": \"/opt/ml/processing/groundtruth\", \"S3UploadMode\": \"EndOfJob\"}}, {\"OutputName\": \"trainbase\", \"AppManaged\": false, \"S3Output\": {\"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/trainbase\", \"LocalPath\": \"/opt/ml/processing/trainbase\", \"S3UploadMode\": \"EndOfJob\"}}]}, \"AppSpecification\": {\"ImageUri\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\", \"ContainerEntrypoint\": [\"python3\", \"/opt/ml/processing/input/code/titanic-preprocessing-linear-learner-script.py\"]}, \"RoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\", \"ProcessingResources\": {\"ClusterConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.xlarge\", \"VolumeSizeInGB\": 30}}}, \"Type\": \"Task\", \"Next\": \"Model Training(linear)\"}, \"Model Training(linear)\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification\": {\"TrainingImage\": \"382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\", \"TrainingInputMode\": \"File\"}, \"OutputDataConfig\": {\"S3OutputPath\": \"s3://ds-mlops-dev/models\"}, \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 86400}, \"ResourceConfig\": {\"VolumeSizeInGB\": 30, \"InstanceCount\": 1, \"InstanceType\": \"ml.m5.xlarge\"}, \"RoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\", \"InputDataConfig\": [{\"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/train/\", \"S3DataDistributionType\": \"FullyReplicated\"}}, \"ContentType\": \"text/csv\", \"ChannelName\": \"train\"}, {\"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": \"s3://ds-mlops-dev/titanic/preprocess-data/validation/\", \"S3DataDistributionType\": \"FullyReplicated\"}}, \"ContentType\": \"text/csv\", \"ChannelName\": \"validation\"}], \"HyperParameters\": {\"epochs\": \"50\", \"l1\": \"0.0014121036264995773\", \"learning_rate\": \"0.012104062065442999\", \"mini_batch_size\": \"256\", \"predictor_type\": \"regressor\"}, \"TrainingJobName.$\": \"$$.Execution.Input['TrainingJobName']\"}, \"Type\": \"Task\", \"Next\": \"Save Model\"}, \"Save Model\": {\"ResultPath\": \"$.ModelStepResults\", \"Parameters\": {\"ExecutionRoleArn\": \"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\", \"ModelName.$\": \"$$.Execution.Input['ModelName']\", \"PrimaryContainer\": {\"Environment\": {}, \"Image\": \"382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\", \"ModelDataUrl.$\": \"$['ModelArtifacts']['S3ModelArtifacts']\"}}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Query Training Results\"}, \"Query Training Results\": {\"Parameters\": {\"FunctionName\": \"LinearLearnerQuery-training-status\", \"Payload\": {\"TrainingJobName.$\": \"$.TrainingJobName\"}}, \"Resource\": \"arn:aws:states:::lambda:invoke\", \"Type\": \"Task\", \"Next\": \"RMSE < Threshold\"}, \"RMSE < Threshold\": {\"Type\": \"Choice\", \"Choices\": [{\"Variable\": \"$['Payload']['trainingMetrics'][0]['Value']\", \"NumericLessThan\": 3000, \"Next\": \"Create Model Endpoint Config\"}], \"Default\": \"Model Accuracy Too Low\"}, \"Model Accuracy Too Low\": {\"Comment\": \"Validation accuracy lower than threshold\", \"Type\": \"Fail\"}, \"Create Model Endpoint Config\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['EndPointConfig']\", \"ProductionVariants\": [{\"InitialInstanceCount\": 1, \"InstanceType\": \"ml.m4.xlarge\", \"ModelName.$\": \"$$.Execution.Input['ModelName']\", \"VariantName\": \"AllTraffic\"}]}, \"Type\": \"Task\", \"Next\": \"Update Model Endpoint\"}, \"Update Model Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['EndPointConfig']\", \"EndpointName.$\": \"$$.Execution.Input['EndpointName']\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-124';\n",
       "    var events = { 'events': [{\"timestamp\": 1660285055.328, \"type\": \"ExecutionStarted\", \"id\": 1, \"previousEventId\": 0, \"executionStartedEventDetails\": {\"input\": \"{\\n    \\\"PreprocessingJobName\\\": \\\"Titanic-ll--preprocessing-73cec0161a0611ed8cef065a32dff597\\\",\\n    \\\"TrainingJobName\\\": \\\"Titanic-ll-training-73cebc881a0611ed8cef065a32dff597\\\",\\n    \\\"EvaluationProcessingJobName\\\": \\\"Titanic-ll--evaluation-73cec2c81a0611ed8cef065a32dff597\\\",\\n    \\\"ModelName\\\": \\\"Titanic-linear-learner-02\\\",\\n    \\\"ScoreJobName\\\": \\\"Titanic-ll-score-73cec52a1a0611ed8cef065a32dff597\\\",\\n    \\\"EndpointName\\\": \\\"Titanic-endpoint-73cec76e1a0611ed8cef065a32dff597\\\",\\n    \\\"EndPointConfig\\\": \\\"Titanic-endpoint-config-73cec99e1a0611ed8cef065a32dff597\\\"\\n}\", \"inputDetails\": {\"truncated\": false}, \"roleArn\": \"arn:aws:iam::525102048888:role/poc-sagemaker-step-functi-MachineLearningWorkflowE-1XFI2UPRXFTXE\"}}, {\"timestamp\": 1660285055.364, \"type\": \"TaskStateEntered\", \"id\": 2, \"previousEventId\": 0, \"stateEnteredEventDetails\": {\"name\": \"Pre-processing\", \"input\": \"{\\n    \\\"PreprocessingJobName\\\": \\\"Titanic-ll--preprocessing-73cec0161a0611ed8cef065a32dff597\\\",\\n    \\\"TrainingJobName\\\": \\\"Titanic-ll-training-73cebc881a0611ed8cef065a32dff597\\\",\\n    \\\"EvaluationProcessingJobName\\\": \\\"Titanic-ll--evaluation-73cec2c81a0611ed8cef065a32dff597\\\",\\n    \\\"ModelName\\\": \\\"Titanic-linear-learner-02\\\",\\n    \\\"ScoreJobName\\\": \\\"Titanic-ll-score-73cec52a1a0611ed8cef065a32dff597\\\",\\n    \\\"EndpointName\\\": \\\"Titanic-endpoint-73cec76e1a0611ed8cef065a32dff597\\\",\\n    \\\"EndPointConfig\\\": \\\"Titanic-endpoint-config-73cec99e1a0611ed8cef065a32dff597\\\"\\n}\", \"inputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1660285055.364, \"type\": \"TaskScheduled\", \"id\": 3, \"previousEventId\": 2, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createProcessingJob.sync\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"ProcessingJobName\\\":\\\"Titanic-ll--preprocessing-bb825652127211eda8ba069fa5025bc9\\\",\\\"ProcessingInputs\\\":[{\\\"InputName\\\":\\\"input\\\",\\\"AppManaged\\\":false,\\\"S3Input\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/data/input/inputdata.csv\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/input\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3InputMode\\\":\\\"File\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3CompressionType\\\":\\\"None\\\"}},{\\\"InputName\\\":\\\"code\\\",\\\"AppManaged\\\":false,\\\"S3Input\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/code/titanic-preprocessing-linear-learner-script.py\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/input/code\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3InputMode\\\":\\\"File\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3CompressionType\\\":\\\"None\\\"}}],\\\"ProcessingOutputConfig\\\":{\\\"Outputs\\\":[{\\\"OutputName\\\":\\\"train_data\\\",\\\"AppManaged\\\":false,\\\"S3Output\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/preprocess-data/train\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/train\\\",\\\"S3UploadMode\\\":\\\"EndOfJob\\\"}},{\\\"OutputName\\\":\\\"test_data\\\",\\\"AppManaged\\\":false,\\\"S3Output\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/preprocess-data/test\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/test\\\",\\\"S3UploadMode\\\":\\\"EndOfJob\\\"}},{\\\"OutputName\\\":\\\"validation_data\\\",\\\"AppManaged\\\":false,\\\"S3Output\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/preprocess-data/validation\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/validation\\\",\\\"S3UploadMode\\\":\\\"EndOfJob\\\"}},{\\\"OutputName\\\":\\\"baselinemodeldrift\\\",\\\"AppManaged\\\":false,\\\"S3Output\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/preprocess-data/baselinemodeldrift\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/baselinemodeldrift\\\",\\\"S3UploadMode\\\":\\\"EndOfJob\\\"}},{\\\"OutputName\\\":\\\"groundtruth\\\",\\\"AppManaged\\\":false,\\\"S3Output\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/preprocess-data/groundtruth\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/groundtruth\\\",\\\"S3UploadMode\\\":\\\"EndOfJob\\\"}},{\\\"OutputName\\\":\\\"trainbase\\\",\\\"AppManaged\\\":false,\\\"S3Output\\\":{\\\"S3Uri\\\":\\\"s3://ds-mlops-dev/titanic/preprocess-data/trainbase\\\",\\\"LocalPath\\\":\\\"/opt/ml/processing/trainbase\\\",\\\"S3UploadMode\\\":\\\"EndOfJob\\\"}}]},\\\"AppSpecification\\\":{\\\"ImageUri\\\":\\\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\\\",\\\"ContainerEntrypoint\\\":[\\\"python3\\\",\\\"/opt/ml/processing/input/code/titanic-preprocessing-linear-learner-script.py\\\"]},\\\"RoleArn\\\":\\\"arn:aws:iam::525102048888:role/service-role/AmazonSageMaker-ExecutionRole-20191105T125227\\\",\\\"ProcessingResources\\\":{\\\"ClusterConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.m5.xlarge\\\",\\\"VolumeSizeInGB\\\":30}},\\\"Tags\\\":[{\\\"Key\\\":\\\"MANAGED_BY_AWS\\\",\\\"Value\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}]}\"}}, {\"timestamp\": 1660285055.4, \"type\": \"TaskStarted\", \"id\": 4, \"previousEventId\": 3, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createProcessingJob.sync\"}}] };\n",
       "\n",
       "    var graph = new sfn.StateMachineExecutionGraph(definition, events, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_workflow_execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6a048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0        1      2                  3   \\\n",
      "530  2022-08-17 03:45:26  XGboost  Batch  53220220817034526   \n",
      "22   2022-08-17 03:45:26  XGboost  Batch   2320220817034526   \n",
      "623  2022-08-17 03:45:26  XGboost  Batch  62520220817034526   \n",
      "535  2022-08-17 03:45:26  XGboost  Batch  53720220817034526   \n",
      "285  2022-08-17 03:45:26  XGboost  Batch  28720220817034526   \n",
      "\n",
      "                                                    4        5         6   \\\n",
      "530  s3://wi-cred-datalake-dev-raw/data/repscoreinp...  Titanic -0.101340   \n",
      "22   s3://wi-cred-datalake-dev-raw/data/repscoreinp...  Titanic -1.103064   \n",
      "623  s3://wi-cred-datalake-dev-raw/data/repscoreinp...  Titanic -0.640730   \n",
      "535  s3://wi-cred-datalake-dev-raw/data/repscoreinp...  Titanic  1.208607   \n",
      "285  s3://wi-cred-datalake-dev-raw/data/repscoreinp...  Titanic  0.052771   \n",
      "\n",
      "           7         8         9   ...  37  38  39  40  41  42  43  44  45  \\\n",
      "530 -0.475199 -0.474326 -0.880201  ...   0   0   0   1   0   0   0   0   0   \n",
      "22  -0.475199 -0.474326 -0.784280  ...   1   0   0   0   0   0   0   0   0   \n",
      "623 -0.475199 -0.474326 -0.124012  ...   0   0   0   1   0   0   0   0   0   \n",
      "535 -0.475199 -0.474326  0.369083  ...   0   0   0   0   0   0   0   0   0   \n",
      "285 -0.475199 -0.474326 -0.628252  ...   0   0   0   1   0   0   0   0   0   \n",
      "\n",
      "           46  \n",
      "530  0.156310  \n",
      "22   0.734594  \n",
      "623  0.125600  \n",
      "535 -0.026647  \n",
      "285  0.071242  \n",
      "\n",
      "[5 rows x 47 columns]\n",
      "           6         7         8         9   10  11  12  13  14  15  ...  37  \\\n",
      "530 -0.101340 -0.475199 -0.474326 -0.880201   0   1   0   0   1   0  ...   0   \n",
      "22  -1.103064 -0.475199 -0.474326 -0.784280   0   1   0   0   1   1  ...   1   \n",
      "623 -0.640730 -0.475199 -0.474326 -0.124012   0   1   0   0   1   0  ...   0   \n",
      "535  1.208607 -0.475199 -0.474326  0.369083   1   1   1   0   0   0  ...   0   \n",
      "285  0.052771 -0.475199 -0.474326 -0.628252   0   1   0   0   1   0  ...   0   \n",
      "\n",
      "     38  39  40  41  42  43  44  45        46  \n",
      "530   0   0   1   0   0   0   0   0  0.156310  \n",
      "22    0   0   0   0   0   0   0   0  0.734594  \n",
      "623   0   0   1   0   0   0   0   0  0.125600  \n",
      "535   0   0   0   0   0   0   0   0 -0.026647  \n",
      "285   0   0   1   0   0   0   0   0  0.071242  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename=\"scorewolabel20220817034014_130312380.csv.out\"\n",
    "#filename=\"badodometersd20220623120734_1889418018.csv.out\"\n",
    "df = pd.read_csv(filename,header=None)\n",
    "df = df.sample(frac=.25)\n",
    "print(df.head(5))\n",
    "df=df.iloc[: ,6:]#.drop([4],axis = 1)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3db379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 120.1 KiB/120.1 KiB (1.0 MiB/s) with 1 file(s) remaining\r",
      "download: s3://wi-cred-datalake-dev-raw/transformed/scoring/outbound/batch/ll/2022/06/23/12/badodometersd20220623120734_1889418018.csv.out to ./badodometersd20220623120734_1889418018.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://wi-cred-datalake-dev-raw/transformed/scoring/outbound/batch/ll/2022/06/23/12/badodometersd20220623120734_1889418018.csv.out ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1947a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_csv(input_path, bkt,output_path,filename,modelname,monitorjobname,mtrrefpath,mdmonitorjobname):\n",
    "    col_name=list()\n",
    "    for i in range(47):#set it to the lenght of scoring table means # of desiered columns same as batch scoring data file\n",
    "        column = 'col_' + str(i)\n",
    "        col_name.append(column)\n",
    "    df = pd.DataFrame(columns=col_name)\n",
    "    i = 0\n",
    "    for line in smart_open(input_path, 'rb'):\n",
    "        input_row = json.loads(line.decode('utf8'))\n",
    "        input_data = input_row['captureData']['endpointInput']['data']\n",
    "        input_data = input_data.split(',')\n",
    "        inference_id = input_row['eventMetadata']['inferenceId']\n",
    "        runtime=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        output = input_row['captureData']['endpointOutput']['data'].replace('\\n', '')\n",
    "        input_data.insert(0, 'Titanic')#added use case name\n",
    "        input_data.insert(0, 'NA for realtime data')\n",
    "        input_data.insert(0, inference_id)\n",
    "        input_data.insert(0, 'realtime')\n",
    "        input_data.insert(0, modelname)\n",
    "        input_data.insert(0, runtime)\n",
    "        \n",
    "        input_data.append(output)\n",
    "        df.loc[i] = input_data\n",
    "        i = i+1\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer,index=False)\n",
    "    s=writecsv(csv_buffer,bkt,output_path+filename+'.csv')\n",
    "    df1=df.iloc[:,3:4] # read the inference id from position\n",
    "    df2=df1.copy(deep=True)\n",
    "    df2.columns=['Inferenceid']\n",
    "    df2['monitorjobname']=monitorjobname\n",
    "    df2['modelname']=modelname\n",
    "    df2['mdmonitorjobname']=mdmonitorjobname\n",
    "    csv_buffer = StringIO()\n",
    "    df2.to_csv(csv_buffer,index=False)\n",
    "    s=writecsv(csv_buffer,bkt,mtrrefpath+filename+'.csv')\n",
    "    return 'Transfer is done'    \n",
    "def writecsv(content,buckname,buckobj):\n",
    "    clnt=boto3.resource('s3')\n",
    "    clnt.Object(buckname, buckobj).put(Body=content.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0261fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "event={\"RTReportPath\": \"transformed/titanic/scoring/outbound/realtime/xg/2022/08/18/04/\",\n",
    "      \"notif_sub\": \"Data Drift Monitor -XGboost - Realtime\",\n",
    "      \"prep_jsonlpath\": \"transformed/titanic/monitoring/inbound/realtime/xg/2022/08/18/04/\",\n",
    "      \"monitoropkey\": \"transformed/titanic/monitoring/outbound/datadrift/realtime/xg/2022/08/18/04/\",\n",
    "      \"modelname\": \"XGboost\",\n",
    "      \"reportopkey\": \"transformed/titanic/monitoring/reporting/drift/realtime/xg/2022/08/18/04/\",\n",
    "      \"inpjsonline\": \"s3://wi-cred-datalake-dev-raw/transformed/titanic/monitoring/inbound/realtime/xg/2022/08/18/04/\",\n",
    "      \"endtime\": \"2022-08-18T05:00:00Z\",\n",
    "      \"outjsonpath\": \"s3://wi-cred-datalake-dev-raw/transformed/titanic/monitoring/outbound/datadrift/realtime/xg/2022/08/18/04/\",\n",
    "      \"starttime\": \"2022-08-18T04:00:00Z\",\n",
    "      \"MonitorJobName\": \"Wi-MLOPS-ModelMonitor-RT-xg-datadrift-3680709594\",\n",
    "      \"infertype\": \"Realtime\",\n",
    "      \"baselinecons\": \"s3://wi-cred-datalake-dev-s3-mlops-config/titanic/training/inbound/baseline/datadrift/constraints.json\",\n",
    "      \"payload_src\": \"transformed/titanic/monitoring/inbound/currentrun/realtime/xg/\",\n",
    "      \"mtrrefpath\": \"transformed/titanic/monitoring/reporting/scoremonitorbridge/realtime/xg/2022/08/18/04/\",\n",
    "      \"MD_MonitorJobName\": \"Wi-MLOPS-ModelMonitor-RT-xg-modeldrift-3680709844\",\n",
    "      \"baselinestat\": \"s3://wi-cred-datalake-dev-s3-mlops-config/titanic/training/inbound/baseline/datadrift/statistics.json\",\n",
    "      \"md_monitoroppath\": \"s3://wi-cred-datalake-dev-raw/transformed/titanic/monitoring/outbound/modeldrift/realtime/xg/2022/08/18/04/\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c3fcff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hirealtimereport\n",
      "hirealtimereport_1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "from io import StringIO\n",
    "from smart_open import smart_open\n",
    "s3_client=boto3.client('s3')\n",
    "output_path=event['RTReportPath']\n",
    "inputJsonpath=event['prep_jsonlpath']\n",
    "monitorjobname=event['MonitorJobName']\n",
    "mdmonitorjobname=event['MD_MonitorJobName']\n",
    "modelname=event['modelname']\n",
    "mtrrefpath=event['mtrrefpath']\n",
    "v_s3_input_bucket=\"wi-cred-datalake-dev-raw\"\n",
    "print(\"hirealtimereport\")\n",
    "response = s3_client.list_objects(Bucket=v_s3_input_bucket,Prefix=inputJsonpath)\n",
    "print(\"hirealtimereport_1\")\n",
    "file_list=list()\n",
    "for i in response['Contents']:\n",
    "    filepath= 's3://'+ v_s3_input_bucket+ '/'+i['Key']\n",
    "    file_list.append(filepath)\n",
    "for i in file_list:\n",
    "    filename=i.split('/')[-1][0:-6]\n",
    "    jsonl_to_csv(i,v_s3_input_bucket,output_path,filename,modelname,monitorjobname,mtrrefpath,mdmonitorjobname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02394d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smart_open\n",
      "  Downloading smart_open-6.0.0-py3-none-any.whl (58 kB)\n",
      "     || 58 kB 6.8 MB/s             \n",
      "\u001b[?25hInstalling collected packages: smart-open\n",
      "Successfully installed smart-open-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install smart_open"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
