{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efdc37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s3://wi-cred-datalake-dev-raw/transformed/nlp/monitoring/inbound/currentrun/batch/turi/run-1666951649550-part-r-00000']\n",
      "hi\n",
      "datacapture.jsonl\n",
      "datacapture.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "#path = r'/opt/ml/processing/input' # Input path\n",
    "#path='/opt/ml/processing/input/data'\n",
    "#all_files = glob.glob(path + \"/*\",recursive=True)\n",
    "all_files=['s3://wi-cred-datalake-dev-raw/transformed/nlp/monitoring/inbound/currentrun/batch/turi/run-1666951649550-part-r-00000']\n",
    "counter = 0\n",
    "print(all_files)\n",
    "for filename in all_files:\n",
    "    print(\"hi\")\n",
    "    df = pd.read_csv(filename,header=None)\n",
    "    df = df.sample(frac=.25)\n",
    "    df=df.iloc[: ,[3,6,7]]#.drop([4],axis = 1)\n",
    "    # Create a multiline json\n",
    "    json_list = json.loads(df.to_json(orient = \"records\"))\n",
    "    output_path = \"datacapture.jsonl\" #path to the linear learner\n",
    "    print(output_path)\n",
    "    counter = counter + 1\n",
    "    data = {}\n",
    "    data[\"captureData\"]={\n",
    "            \"endpointInput\": {\n",
    "                \"observedContentType\": \"text/csv\",\n",
    "                \"mode\": \"INPUT\",\n",
    "                \"data\": \"132,25,113.2,96,269.9,107,229.1,87,7.1,7,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\",\n",
    "                \"encoding\": \"CSV\"\n",
    "            },\n",
    "            \"endpointOutput\": {\n",
    "                \"observedContentType\": \"text/csv; charset=utf-8\",\n",
    "                \"mode\": \"OUTPUT\",\n",
    "                \"data\": \"6295.23876953125\",\n",
    "                \"encoding\": \"CSV\"\n",
    "            }\n",
    "        }\n",
    "    data[\"eventMetadata\"] = {\n",
    "            \"eventId\": \"\",\n",
    "            \"inferenceTime\": \"2\"\n",
    "        }\n",
    "    data[\"eventVersion\"] = \"0\"\n",
    "    i=0\n",
    "    with open(output_path, 'w') as f:\n",
    "        print(output_path)\n",
    "        for item in json_list:\n",
    "            i=i+1\n",
    "            item = list(item.values())\n",
    "            #item.insert(0,'23')\n",
    "            inpitem = ','.join([str(elem) for elem in item])\n",
    "            #outitem = ','.join([str(elem) for elem in item[-1]])\n",
    "            outitem=str(1)#item[-1])\n",
    "            data[\"captureData\"][\"endpointInput\"][\"data\"] = inpitem\n",
    "            data[\"captureData\"][\"endpointOutput\"][\"data\"] =outitem\n",
    "            data[\"eventMetadata\"][\"eventId\"]=str(item[0])\n",
    "            if i==len(json_list):\n",
    "                f.write(\"%s\" % data)\n",
    "            else:\n",
    "                f.write(\"%s\\n\" % data)\n",
    "# Data push\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac3ad79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       6     7  \\\n",
      "0                   col6  col7   \n",
      "1        020221026094939   ham   \n",
      "2        120221026094939   ham   \n",
      "3        220221026094939  spam   \n",
      "4        320221026094939   ham   \n",
      "...                  ...   ...   \n",
      "3996  399520221026094939   ham   \n",
      "3997  399620221026094939   ham   \n",
      "3998  399720221026094939   ham   \n",
      "3999  399820221026094939  spam   \n",
      "4000  399920221026094939  spam   \n",
      "\n",
      "                                                      8     9  \n",
      "0                                                  col8  col9  \n",
      "1     Go until jurong point crazy.. Available only i...     0  \n",
      "2                         Ok lar... Joking wif u oni...   ham  \n",
      "3     Free entry in 2 a wkly comp to win FA Cup fina...   ham  \n",
      "4     U dun say so early hor... U c already then say...   ham  \n",
      "...                                                 ...   ...  \n",
      "3996  I love to cuddle! I want to hold you in my str...   ham  \n",
      "3997                             R u in this continent?   ham  \n",
      "3998  We'll you pay over like  &lt;#&gt; yrs so its ...   ham  \n",
      "3999  Bored housewives! Chat n date now! 0871750.77....   ham  \n",
      "4000  We tried to call you re your reply to our sms ...   ham  \n",
      "\n",
      "[4001 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename,header=None)\n",
    "df=df.iloc[: ,6:]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cbcce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./datacapture.jsonl to s3://wi-cred-datalake-dev-raw/transformed/nlp/monitoring/inbound/batch/turi/2022/10/26/10/datacapture.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp datacapture.jsonl s3://wi-cred-datalake-dev-raw/transformed/nlp/monitoring/inbound/batch/turi/2022/10/26/10/datacapture.jsonl\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
